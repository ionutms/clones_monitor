name: Monitor Repository Clones and Update Traffic Data

on:
  schedule:
    - cron: '0 */2 * * *'     # First job runs at the start of every 2 hours
    - cron: '5 */2 * * *'     # Second job runs 5 minutes after the first job
  workflow_dispatch:  # Allow manual triggering
  push:
    branches:
      - main  # Trigger on pushes to the main branch

jobs:
  monitor-traffic:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout clones_monitor repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0  # Fetch all history for all branches and tags
      
    - name: Setup GitHub CLI
      uses: sersoft-gmbh/setup-gh-cli-action@v2.0.1
      
    - name: Fetch clone and visitor statistics
      env:
        GH_TOKEN: ${{ secrets.TRAFIC_UPDATE_TOKEN }}
        TZ: Europe/Bucharest  # Set timezone to Romania
      run: |
        # Ensure clone CSV exists with header if it doesn't
        if [ ! -f clones_history.csv ]; then
          echo "clone_timestamp,total_clones,unique_clones" > clones_history.csv
        fi
        
        # Ensure visitors CSV exists with header if it doesn't
        if [ ! -f visitors_history.csv ]; then
          echo "visitor_timestamp,total_visitors,unique_visitors" > visitors_history.csv
        fi
        
        # Ensure second repo clone CSV exists with header if it doesn't
        if [ ! -f minimal_adp1032_clones_history.csv ]; then
          echo "clone_timestamp,total_clones,unique_clones" > minimal_adp1032_clones_history.csv
        fi
        
        # Ensure second repo visitors CSV exists with header if it doesn't
        if [ ! -f minimal_adp1032_visitors_history.csv ]; then
          echo "visitor_timestamp,total_visitors,unique_visitors" > minimal_adp1032_visitors_history.csv
        fi

        # Ensure third repo clone CSV exists with header if it doesn't
        if [ ! -f minimal_max14906_clones_history.csv ]; then
          echo "clone_timestamp,total_clones,unique_clones" > minimal_max14906_clones_history.csv
        fi
        
        # Ensure third repo visitors CSV exists with header if it doesn't
        if [ ! -f minimal_max14906_visitors_history.csv ]; then
          echo "visitor_timestamp,total_visitors,unique_visitors" > minimal_max14906_visitors_history.csv
        fi
        
        # First repository to monitor
        repo1="ionutms/KiCAD_Symbols_Generator"
        # Second repository to monitor
        repo2="ionutms/Minimal_ADP1032"
        # Third repository to monitor
        repo3="ionutms/Minimal_MAX14906"
        
        # Fetch clones for the first repository's main branch and append to clone CSV
        gh api "repos/$repo1/traffic/clones?per_page=100&ref=main" | \
        jq -r '
          .clones |
          map([
            (.timestamp | sub("T.*";"") | sub("Z$";"")) ,
            .count,
            .uniques
          ] | @csv)[]
        ' >> clones_history.csv
        
        # Fetch visitors for the first repository's main branch and append to visitors CSV
        gh api "repos/$repo1/traffic/views?per_page=100&ref=main" | \
        jq -r '
          .views |
          map([
            (.timestamp | sub("T.*";"") | sub("Z$";"")) ,
            .count,
            .uniques
          ] | @csv)[]
        ' >> visitors_history.csv
        
        # Fetch clones for the second repository's main branch and append to clone CSV
        gh api "repos/$repo2/traffic/clones?per_page=100&ref=main" | \
        jq -r '
          .clones |
          map([
            (.timestamp | sub("T.*";"") | sub("Z$";"")) ,
            .count,
            .uniques
          ] | @csv)[]
        ' >> minimal_adp1032_clones_history.csv
        
        # Fetch visitors for the second repository's main branch and append to visitors CSV
        gh api "repos/$repo2/traffic/views?per_page=100&ref=main" | \
        jq -r '
          .views |
          map([
            (.timestamp | sub("T.*";"") | sub("Z$";"")) ,
            .count,
            .uniques
          ] | @csv)[]
        ' >> minimal_adp1032_visitors_history.csv

        # Fetch clones for the third repository's main branch and append to clone CSV
        gh api "repos/$repo3/traffic/clones?per_page=100&ref=main" | \
        jq -r '
          .clones |
          map([
            (.timestamp | sub("T.*";"") | sub("Z$";"")) ,
            .count,
            .uniques
          ] | @csv)[]
        ' >> minimal_max14906_clones_history.csv
        
        # Fetch visitors for the third repository's main branch and append to visitors CSV
        gh api "repos/$repo3/traffic/views?per_page=100&ref=main" | \
        jq -r '
          .views |
          map([
            (.timestamp | sub("T.*";"") | sub("Z$";"")) ,
            .count,
            .uniques
          ] | @csv)[]
        ' >> minimal_max14906_visitors_history.csv
    
    - name: Remove duplicate rows from CSVs
      run: |
        # Process clone CSV
        echo "clone_timestamp,total_clones,unique_clones" > clones_history_fixed.csv
        awk '
          BEGIN { FS=OFS="," }
          NR==1 && $1 == "clone_timestamp" { next }
          { data[$1] = $0 }
          END {
            for (timestamp in data) {
              print data[timestamp]
            }
          }
        ' clones_history.csv | sort -t, -k1 >> clones_history_fixed.csv
        mv clones_history_fixed.csv clones_history.csv
        
        # Process visitors CSV
        echo "visitor_timestamp,total_visitors,unique_visitors" > visitors_history_fixed.csv
        awk '
          BEGIN { FS=OFS="," }
          NR==1 && $1 == "visitor_timestamp" { next }
          { data[$1] = $0 }
          END {
            for (timestamp in data) {
              print data[timestamp]
            }
          }
        ' visitors_history.csv | sort -t, -k1 >> visitors_history_fixed.csv
        mv visitors_history_fixed.csv visitors_history.csv
        
        # Process second repo clone CSV
        echo "clone_timestamp,total_clones,unique_clones" > minimal_adp1032_clones_history_fixed.csv
        awk '
          BEGIN { FS=OFS="," }
          NR==1 && $1 == "clone_timestamp" { next }
          { data[$1] = $0 }
          END {
            for (timestamp in data) {
              print data[timestamp]
            }
          }
        ' minimal_adp1032_clones_history.csv | sort -t, -k1 >> minimal_adp1032_clones_history_fixed.csv
        mv minimal_adp1032_clones_history_fixed.csv minimal_adp1032_clones_history.csv
        
        # Process second repo visitors CSV
        echo "visitor_timestamp,total_visitors,unique_visitors" > minimal_adp1032_visitors_history_fixed.csv
        awk '
          BEGIN { FS=OFS="," }
          NR==1 && $1 == "visitor_timestamp" { next }
          { data[$1] = $0 }
          END {
            for (timestamp in data) {
              print data[timestamp]
            }
          }
        ' minimal_adp1032_visitors_history.csv | sort -t, -k1 >> minimal_adp1032_visitors_history_fixed.csv
        mv minimal_adp1032_visitors_history_fixed.csv minimal_adp1032_visitors_history.csv

        # Process third repo clone CSV
        echo "clone_timestamp,total_clones,unique_clones" > minimal_max14906_clones_history_fixed.csv
        awk '
          BEGIN { FS=OFS="," }
          NR==1 && $1 == "clone_timestamp" { next }
          { data[$1] = $0 }
          END {
            for (timestamp in data) {
              print data[timestamp]
            }
          }
        ' minimal_max14906_clones_history.csv | sort -t, -k1 >> minimal_max14906_clones_history_fixed.csv
        mv minimal_max14906_clones_history_fixed.csv minimal_max14906_clones_history.csv
        
        # Process third repo visitors CSV
        echo "visitor_timestamp,total_visitors,unique_visitors" > minimal_max14906_visitors_history_fixed.csv
        awk '
          BEGIN { FS=OFS="," }
          NR==1 && $1 == "visitor_timestamp" { next }
          { data[$1] = $0 }
          END {
            for (timestamp in data) {
              print data[timestamp]
            }
          }
        ' minimal_max14906_visitors_history.csv | sort -t, -k1 >> minimal_max14906_visitors_history_fixed.csv
        mv minimal_max14906_visitors_history_fixed.csv minimal_max14906_visitors_history.csv
    
    - name: Commit and push traffic data to clones_monitor
      env:
        TZ: Europe/Bucharest  # Set timezone to Romania
      run: |
        git config user.name 'GitHub Actions Bot'
        git config user.email '<>'
        
        # Stage all CSV files
        git add clones_history.csv visitors_history.csv minimal_adp1032_clones_history.csv minimal_adp1032_visitors_history.csv minimal_max14906_clones_history.csv minimal_max14906_visitors_history.csv
        
        # Check if there are any changes to commit
        if [[ -n $(git status -s) ]]; then
          git commit -m "Update clone and visitor statistics for $(TZ=Europe/Bucharest date +"%Y-%m-%d %H:%M:%S %Z")"
          git pull --rebase origin main
          git push origin main
        else
          echo "No new traffic data to update"
        fi

  update-repo-traffic:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout clones_monitor repository
      uses: actions/checkout@v4
      with:
        repository: ionutms/clones_monitor
        path: clones_monitor
        token: ${{ secrets.TRAFIC_UPDATE_TOKEN }}
    
    - name: Checkout first repository
      uses: actions/checkout@v4
      with:
        repository: ionutms/KiCAD_Symbols_Generator
        path: repo1
        token: ${{ secrets.TRAFIC_UPDATE_TOKEN }}
    
    - name: Checkout third repository
      uses: actions/checkout@v4
      with:
        repository: ionutms/Minimal_MAX14906
        path: repo3
        token: ${{ secrets.TRAFIC_UPDATE_TOKEN }}
    
    - name: Copy CSV files to repositories
      run: |
        # For first repository
        mkdir -p repo1/repo_traffic_data
        cp clones_monitor/clones_history.csv repo1/repo_traffic_data/clones_history.csv
        cp clones_monitor/visitors_history.csv repo1/repo_traffic_data/visitors_history.csv

        # For ADP1032 data in the first repo
        if [ -f "clones_monitor/minimal_adp1032_clones_history.csv" ]; then
            cp clones_monitor/minimal_adp1032_clones_history.csv repo1/repo_traffic_data/minimal_adp1032_clones_history.csv
        else
            echo "Warning: minimal_adp1032_clones_history.csv not found in clones_monitor directory"
            cp clones_monitor/clones_history.csv repo1/repo_traffic_data/minimal_adp1032_clones_history.csv
        fi

        if [ -f "clones_monitor/minimal_adp1032_visitors_history.csv" ]; then
            cp clones_monitor/minimal_adp1032_visitors_history.csv repo1/repo_traffic_data/minimal_adp1032_visitors_history.csv
        else
            echo "Warning: minimal_adp1032_visitors_history.csv not found in clones_monitor directory"
            cp clones_monitor/visitors_history.csv repo1/repo_traffic_data/minimal_adp1032_visitors_history.csv
        fi

        # For third repository
        mkdir -p repo3/repo_traffic_data
        if [ -f "clones_monitor/minimal_max14906_clones_history.csv" ]; then
            cp clones_monitor/minimal_max14906_clones_history.csv repo3/repo_traffic_data/clones_history.csv
        else
            echo "Warning: minimal_max14906_clones_history.csv not found in clones_monitor directory"
        fi

        if [ -f "clones_monitor/minimal_max14906_visitors_history.csv" ]; then
            cp clones_monitor/minimal_max14906_visitors_history.csv repo3/repo_traffic_data/visitors_history.csv
        else
            echo "Warning: minimal_max14906_visitors_history.csv not found in clones_monitor directory"
        fi

    - name: Commit and push traffic data to first repository
      working-directory: repo1
      run: |
        git config user.name 'GitHub Actions Bot'
        git config user.email '<>'
        
        # Stage all files in the repo_traffic_data directory
        git add -f repo_traffic_data/*

        # Check if there are any changes to commit
        if [[ -n $(git status -s repo_traffic_data) ]]; then
          git commit -m "Update clone and visitor statistics for $(TZ=Europe/Bucharest date +"%Y-%m-%d %H:%M:%S %Z")"
          git pull --rebase origin main
          git push origin main
        else
          echo "No new traffic data to update"
        fi

    - name: Commit and push traffic data to third repository
      working-directory: repo3
      run: |
        git config user.name 'GitHub Actions Bot'
        git config user.email '<>'
        
        # Check if repo_traffic_data exists and has files
        if [ -d "repo_traffic_data" ] && [ "$(ls -A repo_traffic_data)" ]; then
          git add -f repo_traffic_data/*
          # Check if there are any changes to commit
          if [[ -n $(git status -s repo_traffic_data) ]]; then
            git commit -m "Update clone and visitor statistics for $(TZ=Europe/Bucharest date +"%Y-%m-%d %H:%M:%S %Z")"
            git pull --rebase origin main
            git push origin main
          else
            echo "No new traffic data to update"
          fi
        else
          echo "No files in repo_traffic_data. Skipping commit."
        fi