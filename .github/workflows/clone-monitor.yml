name: Monitor Repository Clones and Update Traffic Data

on:
  schedule:
    - cron: '0 */2 * * *'
    - cron: '5 */2 * * *'
  workflow_dispatch:
  push:
    branches: [main]

# Centralized repository configuration - ADD NEW PROJECTS HERE ONLY
env:
  # Repository mapping: prefix=Repository_Name (separated by spaces)
  REPO_CONFIG: |
    kicad_symbols_generator=KiCAD_Symbols_Generator
    minimal_adp1032=Minimal_ADP1032
    minimal_max14906=Minimal_MAX14906
    minimal_ad74413r=Minimal_AD74413R
    modular_software_configurable_io_plc=Modular_Software_Configurable_IO_PLC
    minimal_adin1110=Minimal_ADIN1110
    minimal_ltc9111=Minimal_LTC9111
    minimal_max17761=Minimal_MAX17761
    minimal_lt8304=Minimal_LT8304
    3d_models_vault=3D_Models_Vault
    minimal_max32650=Minimal_MAX32650
    docker_kicad_learning=docker_kicad_learning
    docker_3d_models_hosting=Docker_3D_Models_Hosting
    clones_monitor=clones_monitor

jobs:
  monitor-traffic:
    runs-on: ubuntu-latest
    env:
      TZ: Europe/Bucharest
      GH_TOKEN: ${{ secrets.TRAFIC_UPDATE_TOKEN }}
    
    steps:
    - uses: actions/checkout@v4
      with:
        fetch-depth: 0
    
    - uses: sersoft-gmbh/setup-gh-cli-action@v2.0.1

    - name: Initialize CSV files
      run: |
        # Parse centralized configuration
        declare -A files=()
        while IFS='=' read -r prefix repo_name; do
          if [[ -n "$prefix" && -n "$repo_name" ]]; then
            files["$prefix"]="$repo_name"
          fi
        done <<< "$REPO_CONFIG"
        
        for file_prefix in "${!files[@]}"; do
          # Initialize clones file
          if [ ! -f "${file_prefix}_clones_history.csv" ]; then
            echo "clone_timestamp,total_clones,unique_clones" > "${file_prefix}_clones_history.csv"
          fi
          
          # Initialize visitors file
          if [ ! -f "${file_prefix}_visitors_history.csv" ]; then
            echo "visitor_timestamp,total_visitors,unique_visitors" > "${file_prefix}_visitors_history.csv"
          fi
        done

    - name: Fetch traffic data for last 2 days
      run: |
        fetch_traffic_data() {
          local repo=$1
          local output_prefix=$2
          local type=$3
          local endpoint="clones"
          local output_type="clones"
          
          # Get today and yesterday dates
          local current_date=$(date +"%Y-%m-%d")
          local yesterday_date=$(date -d "yesterday" +"%Y-%m-%d")
          
          if [ "$type" = "visitors" ]; then
            endpoint="views"
            output_type="visitors"
          fi
          
          echo "Processing $type data for $repo (${output_prefix})..."
          
          # Get data from the GitHub API (includes 14 days by default)
          traffic_data=$(gh api "repos/ionutms/$repo/traffic/$endpoint?per_page=100&ref=main")
          
          # Check if we have any data
          if [ -z "$traffic_data" ]; then
            echo "  No data available from GitHub API"
            return
          fi
          
          # Process data for today and yesterday
          for target_date in "$current_date" "$yesterday_date"; do
            echo "  Processing data for $target_date..."
            
            # Check if we have existing data for the target date
            local old_data=""
            if grep -q "^$target_date" "${output_prefix}_${output_type}_history.csv"; then
              old_data=$(grep "^$target_date" "${output_prefix}_${output_type}_history.csv")
              echo "    Found existing data for $target_date: $old_data"
            else
              echo "    No existing data found for $target_date"
            fi
            
            # Extract data for the target date from API response
            day_data=$(echo "$traffic_data" | \
            jq -r "
              .${endpoint} |
              map(select(.timestamp | startswith(\"$target_date\"))) |
              map([
                (.timestamp | sub(\"T.*\";\"\") | sub(\"Z\$\";\"\")) ,
                .count,
                .uniques
              ] | @csv)[]
            ")
            
            # If we have data for the target date, process it
            if [ ! -z "$day_data" ]; then
              echo "    New data for $target_date: $day_data"
              
              # Calculate differences if we had old data
              if [ ! -z "$old_data" ]; then
                local old_total=$(echo "$old_data" | cut -d',' -f2)
                local old_unique=$(echo "$old_data" | cut -d',' -f3)
                local new_total=$(echo "$day_data" | cut -d',' -f2)
                local new_unique=$(echo "$day_data" | cut -d',' -f3)
                
                # Only update if new values are higher (to avoid losing data)
                if (( new_total >= old_total && new_unique >= old_unique )); then
                  local diff_total=$((new_total - old_total))
                  local diff_unique=$((new_unique - old_unique))
                  
                  echo "    Changes to update:"
                  echo "      Total $output_type: $old_total → $new_total ($([ $diff_total -ge 0 ] && echo "+$diff_total" || echo "$diff_total"))"
                  echo "      Unique $output_type: $old_unique → $new_unique ($([ $diff_unique -ge 0 ] && echo "+$diff_unique" || echo "$diff_unique"))"
                else
                  echo "    Keeping existing data as it has higher values"
                  day_data="$old_data"
                fi
              else
                echo "    First data for $target_date: $(echo $day_data | tr ',' ' ')"
              fi
              
              # First create a temporary file with current data excluding target date entries
              grep -v "^$target_date" "${output_prefix}_${output_type}_history.csv" > "${output_prefix}_${output_type}_temp.csv" || touch "${output_prefix}_${output_type}_temp.csv"
              
              # Add header if the temp file is empty
              if [ ! -s "${output_prefix}_${output_type}_temp.csv" ]; then
                if [ "$type" = "visitors" ]; then
                  echo "visitor_timestamp,total_visitors,unique_visitors" > "${output_prefix}_${output_type}_temp.csv"
                else
                  echo "clone_timestamp,total_clones,unique_clones" > "${output_prefix}_${output_type}_temp.csv"
                fi
              fi
              
              # Append target date data
              echo "$day_data" >> "${output_prefix}_${output_type}_temp.csv"
              
              # Replace original file with updated one
              mv "${output_prefix}_${output_type}_temp.csv" "${output_prefix}_${output_type}_history.csv"
              echo "    Updated ${output_prefix}_${output_type}_history.csv with $target_date data"
            else
              echo "    No data available for $target_date from GitHub API"
            fi
          done
          echo ""
        }
        
        # Parse centralized configuration
        declare -A repos=()
        while IFS='=' read -r prefix repo_name; do
          if [[ -n "$prefix" && -n "$repo_name" ]]; then
            repos["$prefix"]="$repo_name"
          fi
        done <<< "$REPO_CONFIG"
        
        for output_prefix in "${!repos[@]}"; do
          fetch_traffic_data "${repos[$output_prefix]}" "$output_prefix" "clones"
          fetch_traffic_data "${repos[$output_prefix]}" "$output_prefix" "visitors"
        done

    - name: Remove duplicate rows
      run: |
        process_csv() {
          local input=$1
          local header=$2
          local temp="${input%.csv}_fixed.csv"
          
          echo "$header" > "$temp"
          awk -F, 'NR>1 { data[$1] = $0 } END { for(k in data) print data[k] }' "$input" | \
            sort -t, -k1 >> "$temp"
          mv "$temp" "$input"
        }
        
        for csv in *_clones_history.csv; do
          process_csv "$csv" "clone_timestamp,total_clones,unique_clones"
        done
        
        for csv in *_visitors_history.csv; do
          process_csv "$csv" "visitor_timestamp,total_visitors,unique_visitors"
        done

    - name: Commit and push traffic data
      run: |
        git config user.name 'GitHub Actions Bot'
        git config user.email '<>'
        git add *_history.csv
        
        if [[ -n $(git status -s) ]]; then
          echo "Changes detected in traffic data files:"
          git diff --staged --stat
          
          # Generate a summary of both today's and yesterday's data for commit message
          current_date=$(date +"%Y-%m-%d")
          yesterday_date=$(date -d "yesterday" +"%Y-%m-%d")
          echo "Generating summary for commit message..."
          
          summary=""
          for date in "$current_date" "$yesterday_date"; do
            for repo_type in clones visitors; do
              for csv_file in *_${repo_type}_history.csv; do
                if grep -q "^$date" "$csv_file"; then
                  repo_name=$(echo "$csv_file" | sed "s/_${repo_type}_history.csv//")
                  data_line=$(grep "^$date" "$csv_file")
                  
                  date_label=$([ "$date" = "$current_date" ] && echo "Today" || echo "Yesterday")
                  
                  if [ "$repo_type" = "clones" ]; then
                    total=$(echo "$data_line" | cut -d',' -f2)
                    unique=$(echo "$data_line" | cut -d',' -f3)
                    summary="$summary\n- $repo_name ($date_label): $total clones ($unique unique)"
                  else
                    total=$(echo "$data_line" | cut -d',' -f2)
                    unique=$(echo "$data_line" | cut -d',' -f3)
                    summary="$summary\n- $repo_name ($date_label): $total views ($unique unique visitors)"
                  fi
                fi
              done
            done
          done
          
          if [ ! -z "$summary" ]; then
            commit_msg="Update clone and visitor statistics for $(date +"%Y-%m-%d %H:%M:%S %Z")\n\nLast 2 days data:$summary"
            git commit -m "$(echo -e "$commit_msg")"
          else
            git commit -m "Update clone and visitor statistics for $(date +"%Y-%m-%d %H:%M:%S %Z")"
          fi
          
          git pull --rebase origin main
          git push origin main
          echo "Successfully pushed updated traffic data"
        else
          echo "No changes detected in traffic data files"
        fi

  update-repo-traffic:
    runs-on: ubuntu-latest
    needs: monitor-traffic
    
    steps:
    - uses: actions/checkout@v4
      with:
        repository: ionutms/clones_monitor
        path: clones_monitor
        token: ${{ secrets.TRAFIC_UPDATE_TOKEN }}
    
    - uses: actions/checkout@v4
      with:
        repository: ionutms/KiCAD_Symbols_Generator
        path: repo1
        token: ${{ secrets.TRAFIC_UPDATE_TOKEN }}
    
    - name: Copy and update traffic data
      run: |
        mkdir -p repo1/repo_traffic_data
        
        # Generate CSV file list dynamically from centralized configuration
        csv_files=()
        while IFS='=' read -r prefix repo_name; do
          if [[ -n "$prefix" && -n "$repo_name" ]]; then
            csv_files+=("${prefix}_clones_history.csv")
            csv_files+=("${prefix}_visitors_history.csv")
          fi
        done <<< "$REPO_CONFIG"
        
        # Copy each file and check if it exists
        for file in "${csv_files[@]}"; do
          if [ -f "clones_monitor/$file" ]; then
            cp "clones_monitor/$file" "repo1/repo_traffic_data/$file"
          else
            echo "Warning: $file not found in clones_monitor directory"
          fi
        done
        
        cd repo1
        git config user.name 'GitHub Actions Bot'
        git config user.email '<>'
        
        if [[ -n $(git status -s repo_traffic_data) ]]; then
          git add -f repo_traffic_data/
          git commit -m "Update clone and visitor statistics for $(TZ=Europe/Bucharest date +"%Y-%m-%d %H:%M:%S %Z")"
          git pull --rebase origin main
          git push origin main
        fi