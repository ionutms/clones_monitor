name: Monitor Repository Clones and Update Traffic Data

on:
  schedule:
    - cron: '0 */2 * * *'     # First job runs at the start of every 2 hours
    - cron: '5 */2 * * *'     # Second job runs 5 minutes after the first job
  workflow_dispatch:  # Allow manual triggering
  push:
    branches:
      - main

# Define repository configurations
env:
  REPOSITORIES: |
    {
      "repos": [
        {
          "name": "KiCAD_Symbols_Generator",
          "prefix": "kicad_symbols_generator"
        },
        {
          "name": "Minimal_ADP1032",
          "prefix": "minimal_adp1032"
        },
        {
          "name": "Minimal_MAX14906",
          "prefix": "minimal_max14906"
        },
        {
          "name": "Minimal_AD74413R",
          "prefix": "minimal_ad74413r"
        },
        {
          "name": "Modular_Software_Configurable_IO_PLC",
          "prefix": "modular_software_configurable_io_plc"
        },
        {
          "name": "Minimal_ADIN1110",
          "prefix": "minimal_adin1110"
        }
      ]
    }

jobs:
  monitor-traffic:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout clones_monitor repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0
      
    - name: Setup GitHub CLI
      uses: sersoft-gmbh/setup-gh-cli-action@v2.0.1
      
    - name: Initialize CSV files
      env:
        TZ: Europe/Bucharest
      run: |
        # Create a function to initialize CSV files
        init_csv() {
          local prefix=$1
          local type=$2
          local file="${prefix}_${type}_history.csv"
          local header="${type}_timestamp,total_${type}s,unique_${type}s"
          
          if [ ! -f "$file" ]; then
            echo "$header" > "$file"
          fi
        }
        
        # Read repositories from JSON and initialize their CSV files
        echo "$REPOSITORIES" | jq -r '.repos[] | .prefix' | while read -r prefix; do
          init_csv "$prefix" "clones"
          init_csv "$prefix" "visitors"
        done

    - name: Fetch traffic statistics
      env:
        GH_TOKEN: ${{ secrets.TRAFIC_UPDATE_TOKEN }}
        TZ: Europe/Bucharest
      run: |
        # Function to fetch traffic data
        fetch_traffic_data() {
          local repo_name=$1
          local prefix=$2
          local type=$3
          local endpoint="traffic/${type}s"
          local output_file="${prefix}_${type}_history.csv"
          
          gh api "repos/ionutms/${repo_name}/${endpoint}?per_page=100&ref=main" | \
          jq -r "
            .${type}s |
            map([
              (.timestamp | sub(\"T.*\";\"\") | sub(\"Z\$\";\"\")) ,
              .count,
              .uniques
            ] | @csv)[]
          " >> "$output_file"
        }
        
        # Process each repository
        echo "$REPOSITORIES" | jq -r '.repos[] | [.name, .prefix] | @tsv' | while IFS=$'\t' read -r name prefix; do
          fetch_traffic_data "$name" "$prefix" "clone"
          fetch_traffic_data "$name" "$prefix" "view"
        done

    - name: Remove duplicate rows from CSVs
      run: |
        # Function to remove duplicates from CSV
        deduplicate_csv() {
          local prefix=$1
          local type=$2
          local input_file="${prefix}_${type}_history.csv"
          local temp_file="${prefix}_${type}_history_fixed.csv"
          local header="${type}_timestamp,total_${type}s,unique_${type}s"
          
          echo "$header" > "$temp_file"
          awk '
            BEGIN { FS=OFS="," }
            NR==1 && $1 == "'${type}_timestamp'" { next }
            { data[$1] = $0 }
            END {
              for (timestamp in data) {
                print data[timestamp]
              }
            }
          ' "$input_file" | sort -t, -k1 >> "$temp_file"
          mv "$temp_file" "$input_file"
        }
        
        # Process each repository
        echo "$REPOSITORIES" | jq -r '.repos[] | .prefix' | while read -r prefix; do
          deduplicate_csv "$prefix" "clones"
          deduplicate_csv "$prefix" "visitors"
        done

    - name: Commit and push traffic data
      env:
        TZ: Europe/Bucharest
      run: |
        git config user.name 'GitHub Actions Bot'
        git config user.email '<>'
        
        # Stage all CSV files
        echo "$REPOSITORIES" | jq -r '.repos[] | .prefix' | while read -r prefix; do
          git add "${prefix}_clones_history.csv" "${prefix}_visitors_history.csv"
        done
        
        # Commit and push if there are changes
        if [[ -n $(git status -s) ]]; then
          git commit -m "Update clone and visitor statistics for $(TZ=Europe/Bucharest date +"%Y-%m-%d %H:%M:%S %Z")"
          git pull --rebase origin main
          git push origin main
        else
          echo "No new traffic data to update"
        fi

  update-repo-traffic:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repositories
      uses: actions/checkout@v4
      with:
        repository: ionutms/clones_monitor
        path: clones_monitor
        token: ${{ secrets.TRAFIC_UPDATE_TOKEN }}

    - name: Checkout main repository
      uses: actions/checkout@v4
      with:
        repository: ionutms/KiCAD_Symbols_Generator
        path: main_repo
        token: ${{ secrets.TRAFIC_UPDATE_TOKEN }}

    - name: Copy CSV files to repository
      run: |
        # Create traffic data directory
        mkdir -p main_repo/repo_traffic_data
        
        # Function to copy CSV files
        copy_csv_files() {
          local prefix=$1
          local source_dir="clones_monitor"
          local dest_dir="main_repo/repo_traffic_data"
          
          for type in clones visitors; do
            local file="${prefix}_${type}_history.csv"
            if [ -f "${source_dir}/${file}" ]; then
              cp "${source_dir}/${file}" "${dest_dir}/${file}"
            else
              echo "Warning: ${file} not found in clones_monitor directory"
            fi
          done
        }
        
        # Process each repository
        echo "$REPOSITORIES" | jq -r '.repos[] | .prefix' | while read -r prefix; do
          copy_csv_files "$prefix"
        done

    - name: Commit and push traffic data to main repository
      working-directory: main_repo
      run: |
        git config user.name 'GitHub Actions Bot'
        git config user.email '<>'
        
        git add -f repo_traffic_data/*
        
        if [[ -n $(git status -s repo_traffic_data) ]]; then
          git commit -m "Update clone and visitor statistics for $(TZ=Europe/Bucharest date +"%Y-%m-%d %H:%M:%S %Z")"
          git pull --rebase origin main
          git push origin main
        else
          echo "No new traffic data to update"
        fi