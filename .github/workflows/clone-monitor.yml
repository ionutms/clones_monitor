name: Monitor Repository Traffic

on:
  schedule:
    - cron: '0 */2 * * *'
    - cron: '5 */2 * * *'
  workflow_dispatch:
  push:
    branches: [main]

jobs:
  monitor-traffic:
    runs-on: ubuntu-latest
    env:
      TZ: Europe/Bucharest
      GH_TOKEN: ${{ secrets.TRAFIC_UPDATE_TOKEN }}
    
    steps:
    - uses: actions/checkout@v4
      with:
        fetch-depth: 0
    
    - uses: sersoft-gmbh/setup-gh-cli-action@v2.0.1

    - name: Initialize CSV files
      run: |
        repos=(
          "kicad_symbols_generator"
          "minimal_adp1032"
          "minimal_max14906"
          "minimal_ad74413r"
          "modular_software_configurable_io_plc"
          "minimal_adin1110"
        )
        
        for repo in "${repos[@]}"; do
          for type in "clones" "visitors"; do
            file="${repo}_${type}_history.csv"
            if [ ! -f "$file" ]; then
              echo "${type%s}_timestamp,total_${type},unique_${type}" > "$file"
            fi
          done
        done

    - name: Fetch traffic data
      run: |
        fetch_traffic() {
          local repo=$1
          local type=$2
          local file_prefix=$3
          
          gh api "repos/ionutms/$repo/traffic/$type?per_page=100&ref=main" | \
          jq -r "
            .${type} |
            map([
              (.timestamp | sub(\"T.*\";\"\") | sub(\"Z\$\";\"\")) ,
              .count,
              .uniques
            ] | @csv)[]
          " >> "${file_prefix}_${type}_history.csv"
        }
        
        repos=(
          "KiCAD_Symbols_Generator:kicad_symbols_generator"
          "Minimal_ADP1032:minimal_adp1032"
          "Minimal_MAX14906:minimal_max14906"
          "Minimal_AD74413R:minimal_ad74413r"
          "Modular_Software_Configurable_IO_PLC:modular_software_configurable_io_plc"
          "Minimal_ADIN1110:minimal_adin1110"
        )
        
        for repo_mapping in "${repos[@]}"; do
          IFS=':' read -r repo_name file_prefix <<< "$repo_mapping"
          fetch_traffic "$repo_name" "clones" "$file_prefix"
          fetch_traffic "$repo_name" "views" "$file_prefix"
        done

    - name: Remove duplicate rows
      run: |
        process_csv() {
          local input=$1
          local temp="${input%.csv}_fixed.csv"
          local header=$(head -n1 "$input")
          
          echo "$header" > "$temp"
          awk -F, 'NR>1 { data[$1] = $0 } END { for(k in data) print data[k] }' "$input" | \
            sort -t, -k1 >> "$temp"
          mv "$temp" "$input"
        }
        
        for file in *_history.csv; do
          process_csv "$file"
        done

    - name: Commit and push updates
      run: |
        git config user.name 'GitHub Actions Bot'
        git config user.email '<>'
        git add *_history.csv
        
        if [[ -n $(git status -s) ]]; then
          git commit -m "Update traffic statistics for $(date +"%Y-%m-%d %H:%M:%S %Z")"
          git pull --rebase origin main
          git push origin main
        fi

  update-repo-traffic:
    runs-on: ubuntu-latest
    needs: monitor-traffic
    
    steps:
    - uses: actions/checkout@v4
      with:
        repository: ionutms/clones_monitor
        path: clones_monitor
        token: ${{ secrets.TRAFIC_UPDATE_TOKEN }}
    
    - uses: actions/checkout@v4
      with:
        repository: ionutms/KiCAD_Symbols_Generator
        path: repo1
        token: ${{ secrets.TRAFIC_UPDATE_TOKEN }}
    
    - name: Copy and update traffic data
      run: |
        mkdir -p repo1/repo_traffic_data
        
        find clones_monitor -name "*_history.csv" -exec cp {} repo1/repo_traffic_data/ \;
        
        cd repo1
        git config user.name 'GitHub Actions Bot'
        git config user.email '<>'
        
        if [[ -n $(git status -s repo_traffic_data) ]]; then
          git add -f repo_traffic_data/
          git commit -m "Update traffic statistics for $(TZ=Europe/Bucharest date +"%Y-%m-%d %H:%M:%S %Z")"
          git pull --rebase origin main
          git push origin main
        fi